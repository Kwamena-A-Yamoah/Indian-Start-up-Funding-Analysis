{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNDING ANALYSIS FOR INDIAN STARTUPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team: Team Namibia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "[**Step 1: Business Understanding**](#Step-1:-Business-Understanding)\n",
    "\n",
    "[**Step 2: Data Understanding**](#Step-2:-Data-Understanding)\n",
    "\n",
    "- [**Load Data**](#Load-Data)\n",
    "- [**Data Quality**](#Check-Data-Quality)\n",
    "- [**Exploratory Data Analysis-EDA**](#Exploratory-Data-Analysis---EDA)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Business Understanding\n",
    "Team Namibia is trying to venture into the Indian start-up ecosystem. As the data expert of the team, we are to investigate the ecosystem and propose the best course of action.\n",
    "\n",
    "#### Problem Statement:\n",
    "Ideas, creativity, and execution are essential for a start-up to flourish. But are they enough? Investors provide start-ups and other entrepreneurial ventures with the capital---popularly known as \"funding\"---to think big, grow rich, and leave a lasting impact.\n",
    "\n",
    "In this project we are investigating the dynamics of startup funding in India over the period from 2018 to 2021. The aim is to understand the trends, sector preferences, investment stages, key investors, and funding Patterns. Additionally, if there have been significant differences in funding amounts across different years and sectors, it can guide the action plan to be taken.\n",
    "\n",
    "#### Objective\n",
    "In this analysis we will provide insights into the startup funding landscape in India from 2018 to 2021 by: \n",
    "- Identifying trends and patterns in funding amounts over the years.\n",
    "- Determining which sectors received the most funding and how sector preferences changed over time.\n",
    "- Understanding the distribution of funding across different stages of startups (e.g., Seed, Series A).\n",
    "- Identifying key investors and their investment behaviors.\n",
    "- Analyzing the geographical distribution of funding within India.\n",
    "\n",
    "#### Analytical Questions\n",
    "1. What are the trends and patterns in funding amounts for startups in India between 2018 to 2021?\n",
    "   - Analyzing the annual and quarterly trends in funding can reveal patterns and growth trajectories. Look for peaks, dips, and any consistent growth patterns over these years.(Amount, Year funded)\n",
    "2. Which sectors received the most funding, and how did sector preferences change over time from 2018 to 2021?\n",
    "   - Identifying which industries or sectors received the most funding can show sectoral preferences and shifts. Understanding how this distribution has evolved over the years can highlight emerging trends and declining interests. (industry, amount, year funded)\n",
    "3. How is the distribution of funding across different stages of startups (e.g., Seed, Series A)?\n",
    "   - Analyzing the funding amounts at different startup stages can provide insights into the investment appetite at various growth phases. It can also help in understanding the maturity and risk preference of investors. (stages, Amount)\n",
    "4. Who are the key investors in Indian startups, and what are their investment behaviors/patterns?\n",
    "   - Identifying the most active investors and analyzing their investment portfolios can shed light on key players in the ecosystem. Understanding their investment patterns can also reveal strategic preferences and alliances.(Investor, amount, industry, stages)\n",
    "5. What is the geographical distribution of startup funding within India, and how has this distribution changed over the years 2018 to 2021?\n",
    "   - Analyzing the geographical distribution of startup funding can show regional hotspots for entrepreneurship and investment. Observing how this has changed over the years can reveal shifts in regional focus and development.(location, year_funded, amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from 2018 is obtained from GitHub in csv format, 2019 data is obtained from google drive in csv format and 2020 to 2021 data is obtained from an SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install pyodbc and python-dotenv if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyodbc  \n",
    "# %pip install python-dotenv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyodbc library to handle ODBC database connections\n",
    "import pyodbc \n",
    "\n",
    "# Import the dotenv function to load environment variables from a .env file\n",
    "from dotenv import dotenv_values \n",
    "\n",
    "# Import the pandas library for data manipulation and analysis\n",
    "import pandas as pd \n",
    "\n",
    "# Import the warnings library to handle warning messages\n",
    "import warnings\n",
    "\n",
    "# Filter out (ignore) any warnings that are raised\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the numpy library for data manipulation and analysis\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing a connection to the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Get the values for the credentials you set in the .env file\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "username = environment_variables.get(\"UID\")\n",
    "password = environment_variables.get(\"PWD\")\n",
    "\n",
    "# Create the connection string using the retrieved credentials\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};MARS_Connection=yes;MinProtocolVersion=TLSv1.2;\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 2020 & 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "            #----------Load 2020 data----------\n",
    "# Establish a connection to the database using the connection string\n",
    "connection = pyodbc.connect(connection_string) \n",
    "\n",
    "# Define the SQL query to select all columns from the specified table\n",
    "query = \"Select * from dbo.LP1_startup_funding2020\"\n",
    "\n",
    "# Execute the SQL query and fetch the result into a pandas DataFrame using the established database connection\n",
    "df_2020 = pd.read_sql(query, connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "           #----------Load 2021 data----------\n",
    "# Establish a connection to the database using the connection string\n",
    "connection = pyodbc.connect(connection_string)\n",
    "\n",
    "# Define the SQL query to select all columns from the specified table\n",
    "query1 = \"Select * from dbo.LP1_startup_funding2020\"\n",
    "\n",
    "# Execute the SQL query and fetch the result into a pandas DataFrame using the established database connection\n",
    "df_2021 = pd.read_sql(query1, connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 2018 & 2019 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2018\n",
    "df_2018 = pd.read_csv(r'C:\\Users\\Pc\\Desktop\\Data analysis\\Azubi Africa\\Career Accelerator\\Indian-Start-up-Funding-Analysis\\Dataset\\startup_funding2018.csv')\n",
    "\n",
    "# Load 2019\n",
    "df_2019 = pd.read_csv(r'C:\\Users\\Pc\\Desktop\\Data analysis\\Azubi Africa\\Career Accelerator\\Indian-Start-up-Funding-Analysis\\Dataset\\startup_funding2019.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_2018' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata_2018\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_2019\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_2020\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_2018' is not defined"
     ]
    }
   ],
   "source": [
    "print(data_2018.columns)\n",
    "print(data_2019.columns)\n",
    "print(data_2020.columns)\n",
    "print(data_2021.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename the columns & Save all the data in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 2018 column: 'Round/Series' to 'Funding Stage'\n",
    "df_2018 = df_2018.rename(columns = {'Round/Series': 'Funding Stage'})\n",
    "\n",
    "# Rename 2019 columns\n",
    "df_2019 = df_2019.rename(columns = {'Company/Brand': 'Company Name', 'Sector': 'Industry', 'Stage': 'Funding Stage', 'Amount($)': 'Amount', 'HeadQuarter': 'Location', 'What it does': 'About Company', 'Founded': 'Year Founded'})\n",
    "\n",
    "# Rename 2020 columns\n",
    "df_2020 = df_2020.rename(columns = {'Company_Brand': 'Company Name', 'Sector': 'Industry', 'Stage': 'Funding Stage', 'HeadQuarter': 'Location', 'What_it_does': 'About Company', 'Founded': 'Year Founded'})\n",
    "\n",
    "# Rename 2021 columns\n",
    "df_2021 = df_2021.rename(columns = {'Company_Brand': 'Company Name', 'Sector': 'Industry', 'Stage': 'Funding Stage', 'HeadQuarter': 'Location', 'What_it_does': 'About Company', 'Founded': 'Year Founded'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Funding Stage</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "      <th>Year Funded</th>\n",
       "      <th>Year Founded</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Brand Marketing, Event Promotion, Marketing, S...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>250000</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Agriculture, Farming</td>\n",
       "      <td>Seed</td>\n",
       "      <td>₹40,000,000</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Credit, Financial Services, Lending, Marketplace</td>\n",
       "      <td>Series A</td>\n",
       "      <td>₹65,000,000</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PayMe India</td>\n",
       "      <td>Financial Services, FinTech</td>\n",
       "      <td>Angel</td>\n",
       "      <td>2000000</td>\n",
       "      <td>Noida, Uttar Pradesh, India</td>\n",
       "      <td>PayMe India is an innovative FinTech organizat...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eunimart</td>\n",
       "      <td>E-Commerce Platforms, Retail, SaaS</td>\n",
       "      <td>Seed</td>\n",
       "      <td>—</td>\n",
       "      <td>Hyderabad, Andhra Pradesh, India</td>\n",
       "      <td>Eunimart is a one stop solution for merchants ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company Name                                           Industry  \\\n",
       "0  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...   \n",
       "1  Happy Cow Dairy                               Agriculture, Farming   \n",
       "2       MyLoanCare   Credit, Financial Services, Lending, Marketplace   \n",
       "3      PayMe India                        Financial Services, FinTech   \n",
       "4         Eunimart                 E-Commerce Platforms, Retail, SaaS   \n",
       "\n",
       "  Funding Stage       Amount                          Location  \\\n",
       "0          Seed       250000       Bangalore, Karnataka, India   \n",
       "1          Seed  ₹40,000,000        Mumbai, Maharashtra, India   \n",
       "2      Series A  ₹65,000,000           Gurgaon, Haryana, India   \n",
       "3         Angel      2000000       Noida, Uttar Pradesh, India   \n",
       "4          Seed            —  Hyderabad, Andhra Pradesh, India   \n",
       "\n",
       "                                       About Company  Year Funded  \\\n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...         2018   \n",
       "1  A startup which aggregates milk from dairy far...         2018   \n",
       "2          Leading Online Loans Marketplace in India         2018   \n",
       "3  PayMe India is an innovative FinTech organizat...         2018   \n",
       "4  Eunimart is a one stop solution for merchants ...         2018   \n",
       "\n",
       "   Year Founded Founders Investor column10  \n",
       "0           NaN      NaN      NaN      NaN  \n",
       "1           NaN      NaN      NaN      NaN  \n",
       "2           NaN      NaN      NaN      NaN  \n",
       "3           NaN      NaN      NaN      NaN  \n",
       "4           NaN      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column to each DataFrame to indicate the year\n",
    "df_2018['Year Funded'] = 2018\n",
    "df_2019['Year Funded'] = 2019\n",
    "df_2020['Year Funded'] = 2020\n",
    "df_2021['Year Funded'] = 2021\n",
    "\n",
    "# Concatenate all DataFrames into one master DataFrame\n",
    "df = pd.concat([df_2018, df_2019, df_2020, df_2021], ignore_index=True)\n",
    "\n",
    "\n",
    "# Print out the new DataFrame to confirm the combination was done correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The columns: 'column10', 'Founders' & 'Year Founded' must be removed as they do not help answer our questions.\n",
    "- Review duplicates.\n",
    "- The \"Company Name\" column does not have any may concerns except a few names with \".com\", \".ai\", \".AI\", \".sh\" and \"+\" present.\n",
    "- In the \"Industry\" column:\n",
    "    - \"—\" must be investgated further using the \"About Company\" column in order to fill it with the right data.\n",
    "    - There are companies with multiple industries in a single row, we need to keep only one and remove the rest.\n",
    "    - We can find the unique values in the column and categorize them under specific industries using \"Regular Expression Models\".\n",
    "- There is a link in the \"Funding Stage\" column at index 178.\n",
    "    - Investigate \"NaN\" and \"None\" present in th \"Funding Stage\" column.\n",
    "- The \"Amount\" column (Prescence of \"₹\", \"$\", \"—\" and \"Undisclosed\"in the column):\n",
    "    - Extract \"₹\" to a new column\n",
    "    - Investigate \"NaN\"\n",
    "    - Replace \"₹\", \"$\" and \"—\" with \"\" in the column\n",
    "    - Investigate \"Undisclosed\"\n",
    "    - Convert the dtype of the column to Int64 as it is in the wrong format.\n",
    "- In the \"Location\" column:\n",
    "    - Investigate \"India, Asia\"\n",
    "    - Investigate \"NaN\"\n",
    "    - Split the column, keep the 1st one(containing cities), \n",
    "        - Join it to the main dataframe \"df\"\n",
    "        - Delete the \"Location\"\n",
    "        - Rename the newly joined to \"Location\"\n",
    "- In the \"Investor\" column:\n",
    "    - Investigate \"NaN\"\n",
    "    - Split the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2725, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company Name        0\n",
       "Industry           31\n",
       "Funding Stage     974\n",
       "Amount            508\n",
       "Location          207\n",
       "About Company       0\n",
       "Year Funded         0\n",
       "Year Founded      981\n",
       "Founders          553\n",
       "Investor          602\n",
       "column10         2721\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company Name', 'Industry', 'Funding Stage', 'Amount', 'Location',\n",
       "       'About Company', 'Year Funded', 'Year Founded', 'Founders', 'Investor',\n",
       "       'column10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unwanted columns & checking data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2725 entries, 0 to 2724\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Company Name   2725 non-null   object\n",
      " 1   Industry       2694 non-null   object\n",
      " 2   Funding Stage  1751 non-null   object\n",
      " 3   Amount         2217 non-null   object\n",
      " 4   Location       2518 non-null   object\n",
      " 5   About Company  2725 non-null   object\n",
      " 6   Year Funded    2725 non-null   int64 \n",
      " 7   Investor       2123 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 170.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dropping unwanted columns\n",
    "df = df.drop(columns=['column10','Founders','Year Founded'])\n",
    "\n",
    "# checking data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Amount column for further information\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 7\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "df_duplicates= df[df.duplicated(keep = False)].sort_values(by= \"Company Name\")\n",
    "\n",
    "# Check for number of duplicates\n",
    "sum_dups= df.duplicated().sum()\n",
    "\n",
    "print(\"Number of duplicates:\", sum_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2718, 8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Confirm the new shape. Rows should be less by 23\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in Industry: 31\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(\"Null values in Industry:\",df[\"Industry\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of '—' in Industry: 30\n"
     ]
    }
   ],
   "source": [
    "# Check total number of '—'\n",
    "dash_count= df[df['Industry']=='—']['Industry'].count()\n",
    "\n",
    "print(\"Number of '—' in Industry:\",dash_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace \"—\" with nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New null values in Industry: 61\n"
     ]
    }
   ],
   "source": [
    "# Replace \"—\" with Nulls\n",
    "df['Industry'] = df['Industry'].replace('—', np.nan)\n",
    "\n",
    "# Check for null values\n",
    "print(\"New null values in Industry:\",df[\"Industry\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the nulls with the determined Industries (obtained from the \"About Company\" column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in Industry after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Mapping of company names to industries\n",
    "company_to_industry = {\n",
    "    \"VMate\": \"Media and Entertainment\",\n",
    "    \"Awign Enterprises\": \"Services (Human Resources)\",\n",
    "    \"TapChief\": \"Services (Consulting / Professional Services)\",\n",
    "    \"KredX\": \"Financial Services\",\n",
    "    \"m.Paani\": \"E-Commerce\",\n",
    "    \"Text Mercato\": \"E-Commerce\",\n",
    "    \"Magicpin\": \"E-Commerce\",\n",
    "\t\"Leap Club\": \"E-Commerce\",\n",
    "\t\"Juicy Chemistry\": \"Services\",\n",
    "\t\"Servify\": \"Retail\",\n",
    "\t\"Wagonfly\": \"Media and Entertainment\",\n",
    "\t\"DrinkPrime\": \"E-Commerce\",\n",
    "\t\"Kitchens Centre\": \"Consumer Durables\",\n",
    "\t\"Innoviti\": \"Services\",\n",
    "\t\"Brick&Bolt\": \"Financial Services\",\n",
    "\t\"Toddle\": \"Real Estate\",\n",
    "\t\"HaikuJAM\": \"IT & BPM\",\n",
    "    \"MissMalini Entertainment\" : \"Entertainment and Media\",\n",
    "    \"Jagaran Microfin\" : \"Microfinance\",\n",
    "    \"FLEECA\" : \"Automotive Services\",\n",
    "    \"WheelsEMI\" : \"Financial Services\",\n",
    "    \"Fric Bergen\" : \"Food and Beverage\",\n",
    "    \"Deftouch\" : \"Gaming\",\n",
    "    \"Corefactors\" : \"Marketing\",\n",
    "    \"Cell Propulsion\" : \"Transportation Technology\",\n",
    "    \"Flathalt\" : \"Real Estate\",\n",
    "    \"dishq\" : \"Food Technology\",\n",
    "    \"Trell\" : \"Social Networking\",\n",
    "    \"HousingMan.com\" : \"Real Estate\",\n",
    "    \"Steradian Semiconductors\" : \"Semiconductor Technology\",\n",
    "    \"SaffronStays\" : \"Travel and Hospitality\",\n",
    "    \"Inner Being Wellness\" : \"Beauty and Wellness\",\n",
    "    \"MySEODoc\" : \"Digital Marketing\",\n",
    "    \"ENLYFT DIGITAL SOLUTIONS PRIVATE LIMITED\" : \"Digital Marketing\",\n",
    "    \"Scale Labs\" : \"E-commerce Solutions\",\n",
    "    \"Roadcast\" : \"Business Services\",\n",
    "    \"Toffee\" : \"Insurance Technology\",\n",
    "    \"ORO Wealth\" : \"Financial Services\",\n",
    "    \"Finwego\" : \"Financial Services\",\n",
    "    \"Cred\" : \"Financial Services\",\n",
    "    \"Origo\" : \"Agriculture\",\n",
    "    \"Sequretek\" : \"Cyber Security\",\n",
    "    \"Avenues Payments India Pvt. Ltd.\" : \"IT Solutions\",\n",
    "    \"Planet11 eCommerce Solutions India (Avenue11)\" : \"Technology\",\n",
    "    \"Iba Halal Care\" : \"Cosmetics\",\n",
    "    \"Togedr\" : \"Activity Discovery and Booking\",\n",
    "    \"Scholify\" : \"Edutech\"    \n",
    "}\n",
    "\n",
    "# Function to fill missing industries based on company name\n",
    "def fill_industry(row):\n",
    "    if pd.isna(row[\"Industry\"]):\n",
    "        return company_to_industry.get(row[\"Company Name\"], row[\"Industry\"])\n",
    "    return row[\"Industry\"]\n",
    "\n",
    "# Apply the function to update the 'Industry' column\n",
    "df[\"Industry\"] = df.apply(fill_industry, axis=1)\n",
    "\n",
    "# Checking the Null value in the 'Industry' column\n",
    "print(\"Null values in Industry after cleaning:\",df['Industry'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract 1 Industry from the 'Industry' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brand Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Financial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E-Commerce Platforms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Industry\n",
       "0       Brand Marketing\n",
       "1           Agriculture\n",
       "2                Credit\n",
       "3    Financial Services\n",
       "4  E-Commerce Platforms"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract the first industry from the 'Industry' column\n",
    "def industry_extract(row):\n",
    "    industries = row['Industry'].split(',')\n",
    "    return industries[0].strip() if len(industries) > 1 else row['Industry']\n",
    "\n",
    "# Apply the function to update the 'Industry' column\n",
    "df['new_industry'] = df.apply(industry_extract, axis=1)\n",
    "    \n",
    "# Remove \"Industry\"\n",
    "df = df.drop(columns=['Industry'])\n",
    "\n",
    "# Rename \"new_industry\" to \"Industry\"\n",
    "df = df.rename(columns={'new_industry': 'Industry'})\n",
    "\n",
    "df[[\"Industry\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the unique values of the \"Industry\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Industries: 454\n"
     ]
    }
   ],
   "source": [
    "# Find unique values in the \"Industry\" column\n",
    "unique1= df[\"Industry\"].unique()\n",
    "\n",
    "# Check for number of unique values in the \"Industry\" column\n",
    "print(f\"Number of unique Industries: {len(unique1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize all Industries into Major Industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Number of unique Industries: 114\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def sector_redistribution(Industry):\n",
    "    if re.search(r'bank|fintech|finance|crypto|account|credit|venture|crowd|blockchain|microfinance|lending|wealth|insurance|mutual fund|funding|invest|neo-bank|online financial service|escrow', Industry, re.IGNORECASE):\n",
    "        return 'Finance and FinTech'\n",
    "    elif re.search(r'e-?commerce|retail|marketplace|e-store|e-tail|e-tailer|consumer|durables|appliances|electronics', Industry, re.IGNORECASE):\n",
    "        return 'E-Commerce and Retail'\n",
    "    elif re.search(r'marketing|advertising|brand|digital marketing|sales|customer loyalty|creative agency|content management', Industry, re.IGNORECASE):\n",
    "        return 'Marketing and Advertising'\n",
    "    elif re.search(r'agriculture|agtech|agr[iy]tech|food|beverage|catering|cooking|dairy|nutrition|soil', Industry, re.IGNORECASE):\n",
    "        return 'Agriculture and Food'\n",
    "    elif re.search(r'health|medical|biotech|pharma|medtech|care|diagnostics|wellness|fitness|personal care|skincare|mental health|life science|alternative medicine|veterinary', Industry, re.IGNORECASE):\n",
    "        return 'Healthcare and Wellness'\n",
    "    elif re.search(r'transport|automotive|vehicle|logistics|delivery|air transport|mobility|car|bike|EV|auto-tech|transportation', Industry, re.IGNORECASE):\n",
    "        return 'Transportation and Mobility'\n",
    "    elif re.search(r'real estate|construction|interior|housing|home decor|commercial real estate|co-?working|co-?living', Industry, re.IGNORECASE):\n",
    "        return 'Real Estate and Construction'\n",
    "    elif re.search(r'media|entertainment|broadcasting|streaming|video|music|gaming|sports|digital entertainment|visual media', Industry, re.IGNORECASE):\n",
    "        return 'Media and Entertainment'\n",
    "    elif re.search(r'education|e-?learning|edtech|training|continuing education|career planning|edutech', Industry, re.IGNORECASE):\n",
    "        return 'Education'\n",
    "    elif re.search(r'renewable|clean energy|solar|environmental|energy|cleantech|sanitation', Industry, re.IGNORECASE):\n",
    "        return 'Energy and Environment'\n",
    "    elif re.search(r'consulting|business services|professional services|customer service|legal|facility|IT & BPM', Industry, re.IGNORECASE):\n",
    "        return 'Professional Services'\n",
    "    elif re.search(r'information technology|IT|tech|technology|cloud|internet of things|iot|big data|saas|cyber security|software|ai|machine learning|robotics|deep tech|data science|api|digital|platform|networking|smart cities', Industry, re.IGNORECASE):\n",
    "        return 'Technology'\n",
    "    elif re.search(r'consumer goods|consumer applications|consumer durables|consumer electronics|consumer appliances|eyewear|jewellery|fashion', Industry, re.IGNORECASE):\n",
    "        return 'Consumer Goods'\n",
    "    elif re.search(r'industrial|manufacturing|automation|industrial automation|packaging', Industry, re.IGNORECASE):\n",
    "        return 'Industrial and Manufacturing'\n",
    "    else:\n",
    "        return Industry\n",
    "    \n",
    "# Apply the function to update the 'Industry' column\n",
    "df['Industry'] = df[\"Industry\"].apply(sector_redistribution)\n",
    "\n",
    "# Find unique values in the \"Industry\" column\n",
    "unique2= df[\"Industry\"].unique()\n",
    "\n",
    "# Check for number of unique values in the \"Industry\" column\n",
    "print(f\"New Number of unique Industries: {len(unique2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
