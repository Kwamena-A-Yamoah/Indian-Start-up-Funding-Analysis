{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNDING ANALYSIS FOR INDIAN STARTUPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team: Team Namibia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "[**Step 1: Business Understanding**](#Step-1:-Business-Understanding)\n",
    "\n",
    "[**Step 2: Data Understanding**](#Step-2:-Data-Understanding)\n",
    "\n",
    "- [**Load Data**](#Load-Data)\n",
    "- [**Data Quality**](#Check-Data-Quality)\n",
    "- [**Exploratory Data Analysis-EDA**](#Exploratory-Data-Analysis---EDA)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Business Understanding\n",
    "Team Namibia is trying to venture into the Indian start-up ecosystem. As the data expert of the team, we are to investigate the ecosystem and propose the best course of action.\n",
    "\n",
    "#### Problem Statement:\n",
    "Ideas, creativity, and execution are essential for a start-up to flourish. But are they enough? Investors provide start-ups and other entrepreneurial ventures with the capital---popularly known as \"funding\"---to think big, grow rich, and leave a lasting impact.\n",
    "\n",
    "In this project we are investigating the dynamics of startup funding in India over the period from 2018 to 2021. The aim is to understand the trends, sector preferences, investment stages, key investors, and funding Patterns. Additionally, if there have been significant differences in funding amounts across different years and sectors, it can guide the action plan to be taken.\n",
    "\n",
    "#### Objective\n",
    "In this analysis we will provide insights into the startup funding landscape in India from 2018 to 2021 by: \n",
    "- Identifying trends and patterns in funding amounts over the years.\n",
    "- Determining which sectors received the most funding and how sector preferences changed over time.\n",
    "- Understanding the distribution of funding across different stages of startups (e.g., Seed, Series A).\n",
    "- Identifying key investors and their investment behaviors.\n",
    "- Analyzing the geographical distribution of funding within India.\n",
    "\n",
    "#### Analytical Questions\n",
    "1. What are the trends and patterns in funding amounts for startups in India between 2018 to 2021?\n",
    "   - Analyzing the annual and quarterly trends in funding can reveal patterns and growth trajectories. Look for peaks, dips, and any consistent growth patterns over these years.(Amount, Year funded)\n",
    "2. Which sectors received the most funding, and how did sector preferences change over time from 2018 to 2021?\n",
    "   - Identifying which industries or sectors received the most funding can show sectoral preferences and shifts. Understanding how this distribution has evolved over the years can highlight emerging trends and declining interests. (industry, amount, year funded)\n",
    "3. How is the distribution of funding across different stages of startups (e.g., Seed, Series A)?\n",
    "   - Analyzing the funding amounts at different startup stages can provide insights into the investment appetite at various growth phases. It can also help in understanding the maturity and risk preference of investors. (stages, Amount)\n",
    "4. Who are the key investors in Indian startups, and what are their investment behaviors/patterns?\n",
    "   - Identifying the most active investors and analyzing their investment portfolios can shed light on key players in the ecosystem. Understanding their investment patterns can also reveal strategic preferences and alliances.(Investor, amount, industry, stages)\n",
    "5. What is the geographical distribution of startup funding within India, and how has this distribution changed over the years 2018 to 2021?\n",
    "   - Analyzing the geographical distribution of startup funding can show regional hotspots for entrepreneurship and investment. Observing how this has changed over the years can reveal shifts in regional focus and development.(location, year_funded, amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from 2018 is obtained from GitHub in csv format, 2019 data is obtained from google drive in csv format and 2020 to 2021 data is obtained from an SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install pyodbc and python-dotenv if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyodbc  \n",
    "# %pip install python-dotenv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyodbc library to handle ODBC database connections\n",
    "import pyodbc \n",
    "\n",
    "# Import the dotenv function to load environment variables from a .env file\n",
    "from dotenv import dotenv_values \n",
    "\n",
    "# Import the pandas library for data manipulation and analysis\n",
    "import pandas as pd \n",
    "\n",
    "# Import the warnings library to handle warning messages\n",
    "import warnings\n",
    "\n",
    "# Filter out (ignore) any warnings that are raised\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the numpy library for data manipulation and analysis\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing a connection to the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Get the values for the credentials you set in the .env file\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "username = environment_variables.get(\"UID\")\n",
    "password = environment_variables.get(\"PWD\")\n",
    "\n",
    "# Create the connection string using the retrieved credentials\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};MARS_Connection=yes;MinProtocolVersion=TLSv1.2;\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 2020 & 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "            #----------Load 2020 data----------\n",
    "# Establish a connection to the database using the connection string\n",
    "connection = pyodbc.connect(connection_string) \n",
    "\n",
    "# Define the SQL query to select all columns from the specified table\n",
    "query = \"Select * from dbo.LP1_startup_funding2020\"\n",
    "\n",
    "# Execute the SQL query and fetch the result into a pandas DataFrame using the established database connection\n",
    "df_2020 = pd.read_sql(query, connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "           #----------Load 2021 data----------\n",
    "# Establish a connection to the database using the connection string\n",
    "connection = pyodbc.connect(connection_string)\n",
    "\n",
    "# Define the SQL query to select all columns from the specified table\n",
    "query1 = \"Select * from dbo.LP1_startup_funding2020\"\n",
    "\n",
    "# Execute the SQL query and fetch the result into a pandas DataFrame using the established database connection\n",
    "df_2021 = pd.read_sql(query1, connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 2018 & 2019 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2018\n",
    "df_2018 = pd.read_csv(r'C:\\Users\\Pc\\Desktop\\Data analysis\\Azubi Africa\\Career Accelerator\\Indian-Start-up-Funding-Analysis\\Dataset\\startup_funding2018.csv')\n",
    "\n",
    "# Load 2019\n",
    "df_2019 = pd.read_csv(r'C:\\Users\\Pc\\Desktop\\Data analysis\\Azubi Africa\\Career Accelerator\\Indian-Start-up-Funding-Analysis\\Dataset\\startup_funding2019.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_2018' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata_2018\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_2019\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_2020\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_2018' is not defined"
     ]
    }
   ],
   "source": [
    "print(data_2018.columns)\n",
    "print(data_2019.columns)\n",
    "print(data_2020.columns)\n",
    "print(data_2021.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename the columns & Save all the data in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 2018 column: 'Round/Series' to 'Funding Stage'\n",
    "df_2018 = df_2018.rename(columns = {'Round/Series': 'Funding Stage'})\n",
    "\n",
    "# Rename 2019 columns\n",
    "df_2019 = df_2019.rename(columns = {'Company/Brand': 'Company Name', 'Sector': 'Industry', 'Stage': 'Funding Stage', 'Amount($)': 'Amount', 'HeadQuarter': 'Location', 'What it does': 'About Company', 'Founded': 'Year Founded'})\n",
    "\n",
    "# Rename 2020 columns\n",
    "df_2020 = df_2020.rename(columns = {'Company_Brand': 'Company Name', 'Sector': 'Industry', 'Stage': 'Funding Stage', 'HeadQuarter': 'Location', 'What_it_does': 'About Company', 'Founded': 'Year Founded'})\n",
    "\n",
    "# Rename 2021 columns\n",
    "df_2021 = df_2021.rename(columns = {'Company_Brand': 'Company Name', 'Sector': 'Industry', 'Stage': 'Funding Stage', 'HeadQuarter': 'Location', 'What_it_does': 'About Company', 'Founded': 'Year Founded'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Funding Stage</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "      <th>Year Funded</th>\n",
       "      <th>Year Founded</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Brand Marketing, Event Promotion, Marketing, S...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>250000</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Agriculture, Farming</td>\n",
       "      <td>Seed</td>\n",
       "      <td>₹40,000,000</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Credit, Financial Services, Lending, Marketplace</td>\n",
       "      <td>Series A</td>\n",
       "      <td>₹65,000,000</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PayMe India</td>\n",
       "      <td>Financial Services, FinTech</td>\n",
       "      <td>Angel</td>\n",
       "      <td>2000000</td>\n",
       "      <td>Noida, Uttar Pradesh, India</td>\n",
       "      <td>PayMe India is an innovative FinTech organizat...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eunimart</td>\n",
       "      <td>E-Commerce Platforms, Retail, SaaS</td>\n",
       "      <td>Seed</td>\n",
       "      <td>—</td>\n",
       "      <td>Hyderabad, Andhra Pradesh, India</td>\n",
       "      <td>Eunimart is a one stop solution for merchants ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company Name                                           Industry  \\\n",
       "0  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...   \n",
       "1  Happy Cow Dairy                               Agriculture, Farming   \n",
       "2       MyLoanCare   Credit, Financial Services, Lending, Marketplace   \n",
       "3      PayMe India                        Financial Services, FinTech   \n",
       "4         Eunimart                 E-Commerce Platforms, Retail, SaaS   \n",
       "\n",
       "  Funding Stage       Amount                          Location  \\\n",
       "0          Seed       250000       Bangalore, Karnataka, India   \n",
       "1          Seed  ₹40,000,000        Mumbai, Maharashtra, India   \n",
       "2      Series A  ₹65,000,000           Gurgaon, Haryana, India   \n",
       "3         Angel      2000000       Noida, Uttar Pradesh, India   \n",
       "4          Seed            —  Hyderabad, Andhra Pradesh, India   \n",
       "\n",
       "                                       About Company  Year Funded  \\\n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...         2018   \n",
       "1  A startup which aggregates milk from dairy far...         2018   \n",
       "2          Leading Online Loans Marketplace in India         2018   \n",
       "3  PayMe India is an innovative FinTech organizat...         2018   \n",
       "4  Eunimart is a one stop solution for merchants ...         2018   \n",
       "\n",
       "   Year Founded Founders Investor column10  \n",
       "0           NaN      NaN      NaN      NaN  \n",
       "1           NaN      NaN      NaN      NaN  \n",
       "2           NaN      NaN      NaN      NaN  \n",
       "3           NaN      NaN      NaN      NaN  \n",
       "4           NaN      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column to each DataFrame to indicate the year\n",
    "df_2018['Year Funded'] = 2018\n",
    "df_2019['Year Funded'] = 2019\n",
    "df_2020['Year Funded'] = 2020\n",
    "df_2021['Year Funded'] = 2021\n",
    "\n",
    "# Concatenate all DataFrames into one master DataFrame\n",
    "df = pd.concat([df_2018, df_2019, df_2020, df_2021], ignore_index=True)\n",
    "\n",
    "\n",
    "# Print out the new DataFrame to confirm the combination was done correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The columns: 'column10', 'Founders' & 'Year Founded' must be removed as they do not help answer our questions.\n",
    "- Review duplicates.\n",
    "- The \"Company Name\" column does not have any may concerns except a few names with \".com\", \".ai\", \".AI\", \".sh\" and \"+\" present.\n",
    "- In the \"Industry\" column:\n",
    "    - \"—\" must be investgated further using the \"About Company\" column in order to fill it with the right data.\n",
    "    - There are companies with multiple industries in a single row, we need to keep only one and remove the rest.\n",
    "    - We can find the unique values in the column and categorize them under specific industries using \"Regular Expression Models\".\n",
    "- There is a link in the \"Funding Stage\" column at index 178.\n",
    "    - There is a link as \"Funding Stage\" \n",
    "    - Investigate \"NaN\" present.\n",
    "    - Investigate \"Undisclosed\"\n",
    "    - Same names are presented differently.\n",
    "- The \"Amount\" column (Prescence of \"₹\", \"$\", \"—\" and \"Undisclosed\"in the column):\n",
    "    - Extract \"₹\" to a new column\n",
    "    - Investigate \"NaN\"\n",
    "    - Replace \"₹\", \"$\" and \"—\" with \"\" in the column\n",
    "    - Investigate \"Undisclosed\"\n",
    "    - Convert the dtype of the column to Int64 as it is in the wrong format.\n",
    "- In the \"Location\" column:\n",
    "    - Investigate \"India, Asia\"\n",
    "    - Investigate \"NaN\"\n",
    "    - Split the column, keep the 1st one(containing cities), \n",
    "        - Join it to the main dataframe \"df\"\n",
    "        - Delete the \"Location\"\n",
    "        - Rename the newly joined to \"Location\"\n",
    "- In the \"Investor\" column:\n",
    "    - Investigate \"NaN\"\n",
    "    - Split the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2725, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company Name        0\n",
       "Industry           31\n",
       "Funding Stage     974\n",
       "Amount            508\n",
       "Location          207\n",
       "About Company       0\n",
       "Year Funded         0\n",
       "Year Founded      981\n",
       "Founders          553\n",
       "Investor          602\n",
       "column10         2721\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company Name', 'Industry', 'Funding Stage', 'Amount', 'Location',\n",
       "       'About Company', 'Year Funded', 'Year Founded', 'Founders', 'Investor',\n",
       "       'column10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unwanted columns & checking data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2725 entries, 0 to 2724\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Company Name   2725 non-null   object\n",
      " 1   Industry       2694 non-null   object\n",
      " 2   Funding Stage  1751 non-null   object\n",
      " 3   Amount         2217 non-null   object\n",
      " 4   Location       2518 non-null   object\n",
      " 5   About Company  2725 non-null   object\n",
      " 6   Year Funded    2725 non-null   int64 \n",
      " 7   Investor       2123 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 170.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dropping unwanted columns\n",
    "df = df.drop(columns=['column10','Founders','Year Founded'])\n",
    "\n",
    "# checking data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Amount column for further information\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 7\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "df_duplicates= df[df.duplicated(keep = False)].sort_values(by= \"Company Name\")\n",
    "\n",
    "# Check for number of duplicates\n",
    "sum_dups= df.duplicated().sum()\n",
    "\n",
    "print(\"Number of duplicates:\", sum_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2718, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Confirm the new shape. Rows should be less by 23\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows with multiple columns missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2438, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find rows with missing data in the \"Amount\" and \"Funding Stage\" columns\n",
    "double_nulls= df[df['Amount'].isna()& df['Funding Stage'].isna()]\n",
    "\n",
    "# Drop them from the database\n",
    "df.drop(double_nulls.index, inplace= True)\n",
    "\n",
    "# Confirm the new shape. Rows should be less by 282\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace \"—\" with nulls\n",
    "- Fill the nulls using the column \"About Company\" as reference\n",
    "- Extract only one Industry from the 'Industry' column\n",
    "- Categorize all Industries into Major Industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"—\" with Nulls\n",
    "df['Industry'] = df['Industry'].replace('—', np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the nulls using the column \"About Company\" as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Mapping of company names to industries\n",
    "company_to_industry = {\n",
    "    \"VMate\": \"Media and Entertainment\",\n",
    "    \"Awign Enterprises\": \"Services (Human Resources)\",\n",
    "    \"TapChief\": \"Services (Consulting / Professional Services)\",\n",
    "    \"KredX\": \"Financial Services\",\n",
    "    \"m.Paani\": \"E-Commerce\",\n",
    "    \"Text Mercato\": \"E-Commerce\",\n",
    "    \"Magicpin\": \"E-Commerce\",\n",
    "\t\"Leap Club\": \"E-Commerce\",\n",
    "\t\"Juicy Chemistry\": \"Services\",\n",
    "\t\"Servify\": \"Retail\",\n",
    "\t\"Wagonfly\": \"Media and Entertainment\",\n",
    "\t\"DrinkPrime\": \"E-Commerce\",\n",
    "\t\"Kitchens Centre\": \"Consumer Durables\",\n",
    "\t\"Innoviti\": \"Services\",\n",
    "\t\"Brick&Bolt\": \"Financial Services\",\n",
    "\t\"Toddle\": \"Real Estate\",\n",
    "\t\"HaikuJAM\": \"IT & BPM\",\n",
    "    \"MissMalini Entertainment\" : \"Entertainment and Media\",\n",
    "    \"Jagaran Microfin\" : \"Microfinance\",\n",
    "    \"FLEECA\" : \"Automotive Services\",\n",
    "    \"WheelsEMI\" : \"Financial Services\",\n",
    "    \"Fric Bergen\" : \"Food and Beverage\",\n",
    "    \"Deftouch\" : \"Gaming\",\n",
    "    \"Corefactors\" : \"Marketing\",\n",
    "    \"Cell Propulsion\" : \"Transportation Technology\",\n",
    "    \"Flathalt\" : \"Real Estate\",\n",
    "    \"dishq\" : \"Food Technology\",\n",
    "    \"Trell\" : \"Social Networking\",\n",
    "    \"HousingMan.com\" : \"Real Estate\",\n",
    "    \"Steradian Semiconductors\" : \"Semiconductor Technology\",\n",
    "    \"SaffronStays\" : \"Travel and Hospitality\",\n",
    "    \"Inner Being Wellness\" : \"Beauty and Wellness\",\n",
    "    \"MySEODoc\" : \"Digital Marketing\",\n",
    "    \"ENLYFT DIGITAL SOLUTIONS PRIVATE LIMITED\" : \"Digital Marketing\",\n",
    "    \"Scale Labs\" : \"E-commerce Solutions\",\n",
    "    \"Roadcast\" : \"Business Services\",\n",
    "    \"Toffee\" : \"Insurance Technology\",\n",
    "    \"ORO Wealth\" : \"Financial Services\",\n",
    "    \"Finwego\" : \"Financial Services\",\n",
    "    \"Cred\" : \"Financial Services\",\n",
    "    \"Origo\" : \"Agriculture\",\n",
    "    \"Sequretek\" : \"Cyber Security\",\n",
    "    \"Avenues Payments India Pvt. Ltd.\" : \"IT Solutions\",\n",
    "    \"Planet11 eCommerce Solutions India (Avenue11)\" : \"Technology\",\n",
    "    \"Iba Halal Care\" : \"Cosmetics\",\n",
    "    \"Togedr\" : \"Activity Discovery and Booking\",\n",
    "    \"Scholify\" : \"Edutech\"    \n",
    "}\n",
    "\n",
    "# Function to fill missing industries based on company name\n",
    "def fill_industry(row):\n",
    "    if pd.isna(row[\"Industry\"]):\n",
    "        return company_to_industry.get(row[\"Company Name\"], row[\"Industry\"])\n",
    "    return row[\"Industry\"]\n",
    "\n",
    "# Apply the function to update the 'Industry' column\n",
    "df[\"Industry\"] = df.apply(fill_industry, axis=1)\n",
    "\n",
    "# Checking the Null value in the 'Industry' column\n",
    "print(\"Null values after cleaning:\",df['Industry'].isna().sum())    # null values changes from 59 to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract only one Industry from the 'Industry' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brand Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Financial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E-Commerce Platforms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Industry\n",
       "0       Brand Marketing\n",
       "1           Agriculture\n",
       "2                Credit\n",
       "3    Financial Services\n",
       "4  E-Commerce Platforms"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract the first industry from the 'Industry' column\n",
    "def industry_extract(row):\n",
    "    industries = row['Industry'].split(',')\n",
    "    return industries[0].strip() if len(industries) > 1 else row['Industry']\n",
    "\n",
    "# Apply the function to update the 'Industry' column\n",
    "df['new_industry'] = df.apply(industry_extract, axis=1)\n",
    "    \n",
    "# Remove \"Industry\"\n",
    "df = df.drop(columns=['Industry'])\n",
    "\n",
    "# Rename \"new_industry\" to \"Industry\"\n",
    "df = df.rename(columns={'new_industry': 'Industry'})\n",
    "\n",
    "df[[\"Industry\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize all Industries into Major Industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Industries: 108\n"
     ]
    }
   ],
   "source": [
    "# Import re library to work with regular expressions \n",
    "import re\n",
    "\n",
    "# Function to categorize the industries into major ones\n",
    "def sector_redistribution(Industry):\n",
    "    if re.search(r'bank|fintech|finance|crypto|account|credit|venture|crowd|blockchain|microfinance|lending|wealth|insurance|mutual fund|funding|invest|neo-bank|online financial service|escrow', Industry, re.IGNORECASE):\n",
    "        return 'Finance and FinTech'\n",
    "    elif re.search(r'e-?commerce|retail|marketplace|e-store|e-tail|e-tailer|consumer|durables|appliances|electronics', Industry, re.IGNORECASE):\n",
    "        return 'E-Commerce and Retail'\n",
    "    elif re.search(r'marketing|advertising|brand|digital marketing|sales|customer loyalty|creative agency|content management', Industry, re.IGNORECASE):\n",
    "        return 'Marketing and Advertising'\n",
    "    elif re.search(r'agriculture|agtech|agr[iy]tech|food|beverage|catering|cooking|dairy|nutrition|soil', Industry, re.IGNORECASE):\n",
    "        return 'Agriculture and Food'\n",
    "    elif re.search(r'health|medical|biotech|pharma|medtech|care|diagnostics|wellness|fitness|personal care|skincare|mental health|life science|alternative medicine|veterinary', Industry, re.IGNORECASE):\n",
    "        return 'Healthcare and Wellness'\n",
    "    elif re.search(r'transport|automotive|vehicle|logistics|delivery|air transport|mobility|car|bike|EV|auto-tech|transportation', Industry, re.IGNORECASE):\n",
    "        return 'Transportation and Mobility'\n",
    "    elif re.search(r'real estate|construction|interior|housing|home decor|commercial real estate|co-?working|co-?living', Industry, re.IGNORECASE):\n",
    "        return 'Real Estate and Construction'\n",
    "    elif re.search(r'media|entertainment|broadcasting|streaming|video|music|gaming|sports|digital entertainment|visual media', Industry, re.IGNORECASE):\n",
    "        return 'Media and Entertainment'\n",
    "    elif re.search(r'education|e-?learning|edtech|training|continuing education|career planning|edutech', Industry, re.IGNORECASE):\n",
    "        return 'Education'\n",
    "    elif re.search(r'renewable|clean energy|solar|environmental|energy|cleantech|sanitation', Industry, re.IGNORECASE):\n",
    "        return 'Energy and Environment'\n",
    "    elif re.search(r'consulting|business services|professional services|customer service|legal|facility|IT & BPM', Industry, re.IGNORECASE):\n",
    "        return 'Professional Services'\n",
    "    elif re.search(r'information technology|IT|tech|technology|cloud|internet of things|iot|big data|saas|cyber security|software|ai|machine learning|robotics|deep tech|data science|api|digital|platform|networking|smart cities', Industry, re.IGNORECASE):\n",
    "        return 'Technology'\n",
    "    elif re.search(r'consumer goods|consumer applications|consumer durables|consumer electronics|consumer appliances|eyewear|jewellery|fashion', Industry, re.IGNORECASE):\n",
    "        return 'Consumer Goods'\n",
    "    elif re.search(r'industrial|manufacturing|automation|industrial automation|packaging', Industry, re.IGNORECASE):\n",
    "        return 'Industrial and Manufacturing'\n",
    "    else:\n",
    "        return Industry\n",
    "    \n",
    "# Apply the function to update the 'Industry' column\n",
    "df['Industry'] = df[\"Industry\"].apply(sector_redistribution)\n",
    "\n",
    "# Find unique values in the \"Industry\" column\n",
    "unique2= df[\"Industry\"].unique()\n",
    "\n",
    "# Check for number of unique values in the \"Industry\" column\n",
    "print(f\"Number of unique Industries: {len(unique2)}\")       # Unique values changes from 425 to 108\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract \"₹\" to a new column\n",
    "- Remove \"₹\", \"$\", \"—\" and \"Undisclosed\" in the column\n",
    "- Change column dtype to \"Int64\" and Convert rupees to dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the symbols into new column (currencies)\n",
    "df['currency'] = df.Amount.str.extract(r'([$₹])')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove \"₹\", \"$\", \"—\" and \"Undisclosed\" in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"$\", \"₹\", \"—\", \",\" symbols and \"Undisclosed\" from the 'Amount' column\n",
    "df['Amount'] = df['Amount'].str.replace('[$₹,—]', '', regex=True)\n",
    "df['Amount'] = df['Amount'].str.replace(r'Undisclosed', '', regex=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column dtype to \"Int64\" and Convert rupees to dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount\n",
       "0       0\n",
       "1  520000\n",
       "2  845000\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Amount to a numeric column\n",
    "df['Amount'] = pd.to_numeric(df['Amount'])\n",
    "\n",
    "# Change the Dtype to Integer\n",
    "df['Amount'] = df['Amount'].astype('Int64')   # \"Amount\" is changed to Int64\n",
    "\n",
    "\n",
    "            #------------Converted all rupees to dollars------------\n",
    "# Give the rate a variable\n",
    "rate = 0.013   # Average rupees to dollars exchange rate from 2018 - 2021\n",
    "\n",
    "# Filter the data for rows that contains \"₹\" in the \"currency\" column\n",
    "rupees = df[df['currency'] == \"₹\"]\n",
    "\n",
    "# Convert all rupees to dollars\n",
    "df['Amount']= rupees['Amount']*rate\n",
    "\n",
    "# Change data type of the \"Amount\" column to integer\n",
    "df['Amount'] = df['Amount'].astype('Int64')\n",
    "\n",
    "# Drop the \"currency\" column\n",
    "df = df.drop(columns=['currency'])\n",
    "\n",
    "# Fill all null values with zeros\n",
    "df['Amount'] = df['Amount'].fillna(0) # This only works in the position\n",
    "\n",
    "\n",
    "df[['Amount']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funding Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change column casing\n",
    "- Remove row with link\n",
    "- Fill nulls with \"Undisclosed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in Funding Stage: 0\n"
     ]
    }
   ],
   "source": [
    "# Change the case of all rows in the \"Funding Stage\" column to proper case\n",
    "df['Funding Stage'] = df['Funding Stage'].str.title()\n",
    "\n",
    "# Remove the row with the link \n",
    "df= df.drop(df[df['Funding Stage'].str.contains('https:', na=False)].index)\n",
    "\n",
    "# Fill all 974 null values with \"Undisclosed\"\n",
    "df['Funding Stage']= df['Funding Stage'].fillna('Undisclosed')\n",
    "\n",
    "# Print\n",
    "print(\"Null values in Funding Stage:\",df['Funding Stage'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize Funding stages to their correct names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Stages: 30\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to categorize the Funding Stage \n",
    "def stage_correction(Stage):\n",
    "    if re.search(r'Angel|Angel Round', Stage, re.IGNORECASE):\n",
    "        return 'Angel'\n",
    "    elif re.search(r'Bridge|Bridge Round', Stage, re.IGNORECASE):\n",
    "        return 'Bridge'\n",
    "    elif re.search(r'Debt|Debt Financing', Stage, re.IGNORECASE):\n",
    "        return 'Debt Financing'\n",
    "    elif re.search(r'Fresh Funding|Funding Round', Stage, re.IGNORECASE):\n",
    "        return 'Funding Round'\n",
    "    elif re.search(r'Pre Seed Round|Pre-Seed|Pre-Seed Round', Stage, re.IGNORECASE):\n",
    "        return 'Pre-Seed'\n",
    "    elif re.search(r'Pre Series A|Pre- Series A|Pre-Series|Pre-Series A|Pre-Series A1', Stage, re.IGNORECASE):\n",
    "        return 'Pre-Series A'\n",
    "    elif re.search(r'Pre Series B|Pre-Series B', Stage, re.IGNORECASE):\n",
    "        return 'Pre-Series B'\n",
    "    elif re.search(r'Seed|Seed A|Seed Fund|Seed Funding|Seed Investment|Seed Round', Stage, re.IGNORECASE):\n",
    "        return 'Seed Round'\n",
    "    elif re.search(r'Pre Series C|Pre-Series C', Stage, re.IGNORECASE):\n",
    "        return 'Pre-Series C'\n",
    "    elif re.search(r'Series A|Series A-1', Stage, re.IGNORECASE):\n",
    "        return 'Series A'\n",
    "    elif re.search(r'Series B|Series B+', Stage, re.IGNORECASE):\n",
    "        return 'Series B'\n",
    "    elif re.search(r'Series D|Series D1', Stage, re.IGNORECASE):\n",
    "        return 'Series D'\n",
    "    else:\n",
    "        return Stage\n",
    "    \n",
    "# Apply the function to update the 'Industry' column\n",
    "df['Funding Stage'] = df['Funding Stage'].apply(stage_correction)\n",
    "\n",
    "# Find unique values in the \"Industry\" column\n",
    "unique3= df[\"Funding Stage\"].unique()\n",
    "\n",
    "# Check for number of unique values in the \"Industry\" column\n",
    "print(f\"Number of unique Stages: {len(unique3)}\")         # unique values changes from 50 to 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Funding Stage</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "      <th>Year Funded</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Investor_1</th>\n",
       "      <th>Investor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>0</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>520000</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Agriculture and Food</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Series A</td>\n",
       "      <td>845000</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "      <td>2018</td>\n",
       "      <td>Finance and FinTech</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PayMe India</td>\n",
       "      <td>Angel</td>\n",
       "      <td>0</td>\n",
       "      <td>Noida, Uttar Pradesh, India</td>\n",
       "      <td>PayMe India is an innovative FinTech organizat...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eunimart</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyderabad, Andhra Pradesh, India</td>\n",
       "      <td>Eunimart is a one stop solution for merchants ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>E-Commerce and Retail</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company Name Funding Stage  Amount                          Location  \\\n",
       "0  TheCollegeFever    Seed Round       0       Bangalore, Karnataka, India   \n",
       "1  Happy Cow Dairy    Seed Round  520000        Mumbai, Maharashtra, India   \n",
       "2       MyLoanCare      Series A  845000           Gurgaon, Haryana, India   \n",
       "3      PayMe India         Angel       0       Noida, Uttar Pradesh, India   \n",
       "4         Eunimart    Seed Round       0  Hyderabad, Andhra Pradesh, India   \n",
       "\n",
       "                                       About Company  Year Funded  \\\n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...         2018   \n",
       "1  A startup which aggregates milk from dairy far...         2018   \n",
       "2          Leading Online Loans Marketplace in India         2018   \n",
       "3  PayMe India is an innovative FinTech organizat...         2018   \n",
       "4  Eunimart is a one stop solution for merchants ...         2018   \n",
       "\n",
       "                    Industry Investor_1 Investor_2  \n",
       "0  Marketing and Advertising    Unknown    Unknown  \n",
       "1       Agriculture and Food    Unknown    Unknown  \n",
       "2        Finance and FinTech    Unknown    Unknown  \n",
       "3         Financial Services    Unknown    Unknown  \n",
       "4      E-Commerce and Retail    Unknown    Unknown  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill nulls with \"Unknown\"\n",
    "df['Investor']= df['Investor'].fillna(\"Unknown\")\n",
    "\n",
    "# Split the column\n",
    "investor_split = df['Investor'].str.rsplit(',', expand=True)\n",
    "\n",
    "# Drop all columns except for \"0\" and \"1\"\n",
    "investor_split= investor_split.drop(investor_split.columns[2:], axis=1)\n",
    "\n",
    "# Assign new column names to the splits\n",
    "investor_split.columns = ['Investor_1', 'Investor_2']\n",
    "\n",
    "# Strip both columns of spaces\n",
    "investor_split[\"Investor_1\"]= investor_split[\"Investor_1\"].str.strip()\n",
    "investor_split[\"Investor_2\"]= investor_split[\"Investor_2\"].str.strip()\n",
    "\n",
    "# Fill the nulls of investor_2 with \"Unknown\"\n",
    "investor_split[\"Investor_2\"]= investor_split[\"Investor_2\"].fillna(\"Unknown\")\n",
    "\n",
    "# Join the investor_split to the existing dataset and delete the Investor column\n",
    "df= df.join(investor_split).drop(\"Investor\", axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exctract cities from the column & Correct all Typos\n",
    "- Fill nulls based on research at \"pitchbook.com\" and \"crunchbase.com\n",
    "- Filter out Cities that are not located in India\n",
    "- Impute missing values of the unfound Locations of companies with \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the first part of the 'Location' column after splitting by a comma. e.g the selection of the city\n",
    "df['Location'] = df['Location'].str.split(pat=',').str[0]\n",
    "\n",
    "# Dictionary of replacements to correct the typos for some locations\n",
    "replacements = {\n",
    "    'Banglore': 'Bengaluru',\n",
    "    'Small Towns': 'Andhra Pradesh',\n",
    "    'Gurugram\\t#REF!': 'Gurugram',\n",
    "    'Samsitpur': 'Bengaluru',\n",
    "    'Telugana': 'Hyderabad',\n",
    "    'Orissia': 'Bengaluru',\n",
    "    'Bangalore City': 'Bengaluru',\n",
    "    'Uttar pradesh': 'Uttar Pradesh'\n",
    "}\n",
    "\n",
    "# Replace typos in the 'Location' column with the correct names\n",
    "df['Location'] = df['Location'].replace(replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research was done using \"pitchbook.com\" and \"crunchbase.com\" to discover the location of these startups (with missing values) and inpute their location into the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill nulls based on research at \"pitchbook.com\" and \"crunchbase.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionary mapping company names to locations for companies where Location was the only column missing\n",
    "company_to_location = {\n",
    "    'Habitat': 'Chennai',\n",
    "    'Raskik': 'Gurugram',\n",
    "    'Otipy': 'Gurugram',\n",
    "    'Daalchini': 'Noida',\n",
    "    'Bijnis': 'New Delhi',\n",
    "    'Oziva': 'Mumbai',\n",
    "    'Jiffy ai': 'Bengaluru',\n",
    "    'Juicy Chemistry': 'Coimbatore',\n",
    "    'Shiprocket': 'Gurugram',\n",
    "    'Phable': 'Bengaluru',\n",
    "    'NIRA': 'Bengaluru',\n",
    "    'Setu': 'Bengaluru',\n",
    "    'Zupee': 'Gurugram',\n",
    "    'DeHaat': 'Patna',\n",
    "    'CoinDCX': 'Mumbai',\n",
    "    'Smart Coin': 'Bengaluru',\n",
    "    'Shop101': 'Mumbai',\n",
    "    'Neeman': 'Hyderabad',\n",
    "    'SmartVizX': 'Noida',\n",
    "    'Onsitego': 'Mumbai',\n",
    "    'HempStreet': 'Delhi',\n",
    "    'Classplus': 'Noida',\n",
    "    'Fleetx': 'Gurugram',\n",
    "    'Oye! Rickshaw': 'Delhi',\n",
    "    'MoneyTap': 'Bengaluru',\n",
    "    'LogiNext': 'Mumbai',\n",
    "    'Skylo': 'Bengaluru',\n",
    "    'Samya AI': 'Bengaluru',\n",
    "    'Kristal AI': 'Bengaluru',\n",
    "    'Invento Robotics': 'Bengaluru',\n",
    "    'Teach Us': 'Mumbai',\n",
    "    'Phenom People': 'Hyderabad',\n",
    "    'TechnifyBiz': 'Delhi',\n",
    "    'Klub': 'Bengaluru',\n",
    "    'Techbooze': 'Delhi',\n",
    "    'Testbook': 'Gurugram',\n",
    "    'Mamaearth': 'Gurugram',\n",
    "    'EpiFi': 'Bengaluru',\n",
    "    'Vidyakul': 'Gurugram',\n",
    "    'Pristyn Care': 'Gurugram',\n",
    "    'Springboard': 'Bengaluru',\n",
    "    'Bijak': 'Gurugram',\n",
    "    'Rivigo': 'Gurugram',\n",
    "    'Cubical Labs': 'Delhi'\n",
    "}\n",
    "\n",
    "# Function to fill location based on company name\n",
    "def update_location(row):\n",
    "    if row['Company Name'] in company_to_location:\n",
    "        return company_to_location[row['Company Name']]\n",
    "    return row['Location']\n",
    "\n",
    "# Apply the function on the location column\n",
    "df['Location'] = df.apply(update_location, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out Cities that are not located in India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of cities that are not located in India\n",
    "non_indian_cities = [\n",
    "    \"Singapore\", \"Frisco\", \"California\", \"New York\", \"San Francisco\", \"San Ramon\",\n",
    "    \"Paris\", \"Plano\", \"Sydney\", \"San Francisco Bay Area\", \"Bangaldesh\", \"London\",\n",
    "    \"Milano\", \"Palmwoods\", \"France\", \"Irvine\", \"Newcastle Upon Tyne\", \"Shanghai\",\n",
    "    \"Jiaxing\", \"San Franciscao\", \"Tangerang\", \"Berlin\", \"Seattle\", \"Riyadh\", \"Seoul\",\n",
    "    \"Bangkok\", \"Hyderebad\", \"Computer Games\", \"Food & Beverages\", \"Pharmaceuticals #REF!\",\n",
    "    \"Beijing\", \"Santra\", \"Mountain View\", \"Online Media #REF!\", \"Information Technology & Services\"\n",
    "]\n",
    "\n",
    "# Filter the dataframe to exclude rows with cities that do not belong\n",
    "df = df[~df['Location'].isin(non_indian_cities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Funding Stage</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "      <th>Year Funded</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Investor_1</th>\n",
       "      <th>Investor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>520000</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Agriculture and Food</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Series A</td>\n",
       "      <td>845000</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "      <td>2018</td>\n",
       "      <td>Finance and FinTech</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PayMe India</td>\n",
       "      <td>Angel</td>\n",
       "      <td>0</td>\n",
       "      <td>Noida</td>\n",
       "      <td>PayMe India is an innovative FinTech organizat...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eunimart</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Eunimart is a one stop solution for merchants ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>E-Commerce and Retail</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company Name Funding Stage  Amount   Location  \\\n",
       "0  TheCollegeFever    Seed Round       0  Bangalore   \n",
       "1  Happy Cow Dairy    Seed Round  520000     Mumbai   \n",
       "2       MyLoanCare      Series A  845000    Gurgaon   \n",
       "3      PayMe India         Angel       0      Noida   \n",
       "4         Eunimart    Seed Round       0  Hyderabad   \n",
       "\n",
       "                                       About Company  Year Funded  \\\n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...         2018   \n",
       "1  A startup which aggregates milk from dairy far...         2018   \n",
       "2          Leading Online Loans Marketplace in India         2018   \n",
       "3  PayMe India is an innovative FinTech organizat...         2018   \n",
       "4  Eunimart is a one stop solution for merchants ...         2018   \n",
       "\n",
       "                    Industry Investor_1 Investor_2  \n",
       "0  Marketing and Advertising    Unknown    Unknown  \n",
       "1       Agriculture and Food    Unknown    Unknown  \n",
       "2        Finance and FinTech    Unknown    Unknown  \n",
       "3         Financial Services    Unknown    Unknown  \n",
       "4      E-Commerce and Retail    Unknown    Unknown  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values in the Location column with Unknown\n",
    "df['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
